{
	"if": {
		"prefix": [
			"if"
		],
		"body": [
			"if ${1:condition}:",
			"  $0"
		]
	},
	"for_in": {
		"prefix": [
			"forin",
			"for_in"
		],
		"body": [
			"for ${2:item} in ${1:iterable}:",
			"  $0"
		]
	},
	"dict": {
		"prefix": [
			"dict"
		],
		"body": [
			"my_dict = {",
			"  \"$1\": \"$2\"",
			"  $0",
			"}"
		]
	},
	"lambda": {
		"prefix": [
			"lamb",
			"lambda"
		],
		"body": [
			"lambda x: $0"
		]
	},
	"open_file": {
		"prefix": [
			"open_file",
			"read",
			"open"
		],
		"body": [
			"with open($1) as file:",
			"  data = file.read()$0"
		]
	},
	"func": {
		"prefix": [
			"def",
			"fun",
			"func"
		],
		"body": [
			"def $1($2):",
			"  $0"
		]
	},
	"write_file": {
		"prefix": [
			"write",
			"write_file"
		],
		"body": [
			"with open($1, 'w') as file:",
			"  file.write('Hi there!')$0"
		]
	},
	"list_comp": {
		"description": "List comprehension",
		"prefix": [
			"comprehension",
			"list_comp",
			"listcomp",
			"comp"
		],
		"body": [
			"[${2:x * 2} for x in ${1:mylist}]"
		]
	},
	"list_comp_conditional": {
		"description": "Conditional list comprehension",
		"prefix": [
			"comprehension_conditional",
			"list_comp_conditional",
			"listcomp_conditional",
			"comp_conditional"
		],
		"body": [
			"[${3:x * 2} for x in ${1:mylist} ${2:if x > 2}]"
		]
	},
	"main": {
		"prefix": [
			"main"
		],
		"body": [
			"if __name__ == '__main__':",
			"  $0"
		]
	},
	"shebang": {
		"prefix": [
			"shebang"
		],
		"body": [
			"#!/usr/bin/python3"
		]
	},
	"subprocess": {
		"description": "Call a sub process and capture the output in a string",
		"prefix": [
			"subprocess",
			"check_output"
		],
		"body": [
			"import subprocess",
			"output = subprocess.check_output(['mycmd', 'myarg'])"
		]
	},
	"subprocess_try": {
		"description": "subprocess.check_output with catch for process error",
		"prefix": [
			"subprocess_try",
			"subprocess_try_catch"
		],
		"body": [
			"try:",
			"\toutput = subprocess.check_output(RUN_SCRAPER, stderr=subprocess.STDOUT)",
			"except subprocess.CalledProcessError as e:",
			"\tprint(e.output)"
		]
	},
	"bg_process": {
		"prefix": [
			"bg_process",
			"background",
			"subprocess"
		],
		"body": [
			"import subprocess",
			"ls_output = subprocess.Popen(['${1:sleep}', '30'])",
			"# Dont run this if you want it to be non-blocking (background) ",
			"# ls_output.communicate()  # Will block for 30 seconds"
		]
	},
	"filter": {
		"prefix": [
			"filter"
		],
		"body": [
			"filter(${1:lambda i: i < 5}, ${2:mylist})"
		]
	},
	"map": {
		"prefix": [
			"map"
		],
		"body": [
			"map(${1:lambda: x: x * 2}, ${2:mylist})"
		]
	},
	"list_push": {
		"prefix": [
			"list_push",
			"push",
			"append"
		],
		"body": [
			".append('item')"
		]
	},
	"list_find": {
		"prefix": [
			"list_find",
			"find",
			"index"
		],
		"body": [
			".index(myval)"
		]
	},
	"reduce": {
		"prefix": [
			"py_reduce",
			"reduce"
		],
		"body": [
			"from functools import reduce",
			"reduce(lambda accum, item: accum * item, mylist, 4)"
		]
	},
	"path_join": {
		"prefix": ["path_join", "join", "os_join"],
		"description": "Join paths intelligently",
		"body": [
			"import os",
			"os.path.join(path)"
		]
	},
	"starts_with": {
		"prefix": ["starts_with", "startswith"],
		"description": "String starts with",
		"body": [
			"str.startswith(prefix)"
		]
	},
	"ends_with": {
		"prefix": ["ends_with", "endswith"],
		"description": "String ends with",
		"body": [
			"str.endswith(suffix)"
		]
	},
	"import_json": {
		"prefix": [
			"json",
			"import_json"
		],
		"description": "Import json",
		"body": [
			"import json"
		]
	},
	"json_dumps": {
		"prefix": [
			"json_dumps",
			"dumps_json"
		],
		"description": "JSON dumps dict to string",
		"body": [
			"mystr = json.dumps(${1:data}, sort_keys=True, indent=4)"
		]
	},
	"json_write": {
		"prefix": [
			"json_write",
			"write_json",
			"json_dump_file",
			"dump_json_file"
		],
		"description": "JSON write to file",
		"body": [
			"with open('${1:data.txt}', 'w') as f:",
			"\tjson.dump(${2:data}, f)"
		]
	},
	"json_load": {
		"prefix": [
			"json_load",
			"load_json",
			"json_read",
			"read_json"
		],
		"description": "JSON load from file",
		"body": [
			"with open('data.txt') as json_file:",
			"\tdata = json.load(json_file)"
		]
	},
	"to_int": {
		"prefix": [
			"to_int"
		],
		"body": [
			"int(${1:str})"
		]
	},
	"import_psycopg": {
		"prefix": [
			"import_psycopg",
			"psycopg_import"
		],
		"body": [
			"import psycopg2"
		]
	},
	"psycopg_connect": {
		"prefix": [
			"psycopg_connect",
			"connect"
		],
		"body": [
			"with psycopg2.connect(dbname='db', user='user', password='pass', host='host', port=5432, connect_timeout=3) as conn:",
			"  $0"
		]
	},
	"psycopg_query": {
		"prefix": [
			"psycopg_query",
			"query",
			"fetchall",
			"psycopg_fetchall",
			"psycopg_fetch"
		],
		"body": [
			"with conn.cursor() as curs:",
			"  curs.execute(${1:'sql'})",
			"  data = curs.fetchall()"
		]
	},
	"import_datasci": {
		"prefix": "import_datasci",
		"body": [
			"import numpy as np",
			"import pandas as pd",
			"import matplotlib.pyplot as plt",
			"import seaborn as sns",
			"",
			"%matplotlib inline"
		]
	},
	"pandas_fillna": {
		"prefix": ["pandas_fillna", "fillna", "fill_na"],
		"description": "Pandas fill / clear NAs",
		"body": [
			"df.fillna(0)"
		]
	},
	"pandas_pivot": {
		"prefix": [
			"pandas_pivot"
		],
		"body": [
			"df.pivot_table(values='passenger', index='month', 'columns='year', aggfunc=len)"
		]
	},
	"pandas_dataframe": {
		"prefix": [
			"pandas_dataframe",
			"dataframe"
		],
		"body": [
			"df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})"
		]
	},
	"pandas_dataframe_numpy": {
		"prefix": [
			"pandas_dataframe_numpy",
			"dataframe_numpy",
			"dataframe_array"
		],
		"body": [
			"df = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),",
			"\tcolumns=['a', 'b', 'c'])"
		]
	},
	"pandas_json": {
		"prefix": "pandas_json",
		"body": [
			"df = pd.read_json('my_json.json')"
		]
	},
	"pandas_csv": {
		"prefix": "pandas_csv",
		"body": [
			"df = pd.read_csv('my_csv.csv')"
		]
	},
	"pandas_info": {
		"prefix": "pandas_info",
		"body": [
			"df.head()",
			"df.info()",
			"df.dtypes"
		]
	},
	"pandas_sort": {
		"description": "Pandas sort",
		"prefix": [
			"pandas_sort",
			"sort"
		],
		"body": [
			"df.sort_values(by='foo')"
		]
	},
	"pandas_group": {
		"description": "Pandas group by",
		"prefix": "pandas_group",
		"body": [
			"df_counted = df.groupby(['col1', 'col2']).count()"
		]
	},
	"pandas_apply": {
		"description": "Pandas apply (map)",
		"prefix": [
			"pandas_apply",
			"pandas_map"
		],
		"body": [
			"df['sqrt_values'] = df['values'].apply(np.sqrt)"
		]
	},
	"sns_iris": {
		"description": "Iris dataset (Seaborn)",
		"prefix": [
			"data_iris",
			"sns_iris",
			"seaborn_iris"
		],
		"body": [
			"iris = sns.load_dataset('iris')"
		]
	},
	"sns_pairgrid": {
		"description": "Seaborn grid of regression pairs",
		"prefix": [
			"pairgrid",
			"sns_pairgrid",
			"seaborn_pairgrid",
			"pairgrid",
			"sns_grid",
			"seaborn_grid"
		],
		"body": [
			"g = sns.PairGrid(df)",
			"g.map(plt.scatter)"
		]
	},
	"sns_pairplot": {
		"prefix": [
			"pairplot",
			"sns_pairplot",
			"seaborn_pairplot"
		],
		"body": [
			"sns.pairplot(df)"
		]
	},
	"sns_bar": {
		"description": "Seaborn bar plot",
		"prefix": [
			"barplot",
			"sns_bar",
			"sns_barplot",
			"seaborn_bar",
			"seaborn_barplot"
		],
		"body": [
			"sns.barplot(x='sex', y='survived', hue='class', data=df)"
		]
	},
	"sns_countplot": {
		"description": "Seaborn count plot",
		"prefix": [
			"countplot",
			"sns_countplot",
			"seaborn_countplot"
		],
		"body": [
			"sns.countplot(x='sex', data=df)"
		]
	},
	"sns_dist": {
		"description": "Seaborn dist plot",
		"prefix": [
			"dist",
			"distribution",
			"sns_dist",
			"seaborn_dist",
			"sns_distribution",
			"seaborn_distribution"
		],
		"body": [
			"sns.distplot(df['bill'])"
		]
	},
	"sns_lineplot": {
		"description": "Seaborn line plot",
		"prefix": [
			"sns_lineplot",
			"lineplot",
			"seaborn_lineplot"
		],
		"body": [
			"sns.lineplot(x='timepoint', y='signal', data=df)"
		]
	},
	"sns_heatmap": {
		"description": "Seaborn heatmap",
		"prefix": [
			"sns_heatmap",
			"heatmap",
			"seaborn_heatmap"
		],
		"body": [
			"sns.heatmap(df)"
		]
	},
	"sns_regression": {
		"description": "Seaborn regression plot",
		"prefix": [
			"sns_regression",
			"regression_plot",
			"seaborn_regression"
		],
		"body": [
			"sns.regplot(x='timepoint', y='signal', data=df)"
		]
	},
	"sklearn_linear": {
		"prefix": "sklearn_linear",
		"body": [
			"from sklearn.linear_model import LinearRegression"
		]
	},
	"sklearn_logistic": {
		"prefix": "sklearn_logistic",
		"body": [
			"from sklearn.linear_model import LogisticRegression"
		]
	},
	"sklearn_model": {
		"prefix": "sklearn_model",
		"body": [
			"model = LinearRegression(normalize = True)"
		]
	},
	"sklearn_train_test_split": {
		"prefix": "sklearn_train_test_split",
		"body": [
			"# Where `X` is the data df and `y` is the labels df/series.",
			"from sklearn.model_selection import train_test_split #previously from sklearn.cross_validation",
			"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
		]
	},
	"sklearn_fit": {
		"prefix": "sklearn_fit",
		"body": [
			"model.fit(X_train, y_train)"
		]
	},
	"sklearn_predict": {
		"prefix": "sklearn_predict",
		"body": [
			"predictions = model.predict(X_test)"
		]
	},
	"sklearn_metrics": {
		"prefix": "sklearn_metrics",
		"body": [
			"from sklearn import metrics",
			"",
			"metrics.mean_absolute_error(y_test, predictions)",
			"metrics.mean_squared_error(y_test, predictions)",
			"np.sqrt(metrics.mean_squared_error(y_test, predictions))"
		]
	},
	"sklearn_classification": {
		"prefix": "sklearn_classification",
		"body": [
			"from sklearn.metrics import classification_report",
			"print(classification_report(y_test,predictions))"
		]
	},
	"sklearn_confusion": {
		"prefix": "sklearn_confusion",
		"body": [
			"from sklearn.metrics import confusion_matrix",
			"print(confusion_matrix(y_true, y_pred))"
		]
	},
	"import_torch": {
		"description": "Pytorch import",
		"prefix": [
			"import_torch",
			"import_pytorch",
			"i_torch"
		],
		"body": [
			"import torch"
		]
	},
	"torch_from_numpy": {
		"description": "Pytorch tensor from numpy",
		"prefix": [
			"torch_from_numpy",
			"torch_numpy"
		],
		"body": [
			"torch.from_numpy(${1:np.array([1,2,3])})"
		]
	},
	"torch_tensor": {
		"description": "Pytorch tensor from numpy",
		"prefix": [
			"torch_tensor",
			"tensor",
			"torch_copy"
		],
		"body": [
			"torch.tensor(${1:np.array([1,2,3])})"
		]
	},
	"torch_empty": {
		"description": "Pytorch empty tensor",
		"prefix": "torch_empty",
		"body": [
			"torch.empty(${1:4}, ${2:3})"
		]
	},
	"torch_rand": {
		"description": "Pytorch random tensor",
		"prefix": "torch_rand",
		"body": [
			"torch.rand(${1:4}, ${2:3})"
		]
	},
	"torch_shape": {
		"description": "Pytorch get shape",
		"prefix": [
			"torch_shape",
			"shape"
		],
		"body": [
			"${1:x}.shape"
		]
	},
	"torch_reshape": {
		"description": "Pytorch reshape",
		"prefix": [
			"torch_reshape",
			"reshape",
			"view"
		],
		"body": [
			"${1:x}.reshape(${2:rows}, ${3:cols})"
		]
	},
	"torch_get": {
		"description": "Pytorch -- get row and col",
		"prefix": [
			"torch_get"
		],
		"body": [
			"${1:x}[${2:row},${3:col}]"
		]
	},
	"cdk_usage_comment": {
		"description": "AWS CDK usage / help",
		"prefix": [
			"cdk_usage_comment",
			"cdk",
			"cdk_usage",
			"cdk_help",
			"aws_help"
		],
		"body": [
			"# CDK INSTALL: ",
			"#   npm install -g aws-cdk ",
			"#",
			"# CDK CLI: ",
			"#   cdk init ",
			"#   cdk deploy ",
			"#   cdk destroy ",
			"#",
			"# CDK requirements.txt: ",
			"#   aws-cdk.aws-events",
			"#   aws-cdk.aws-events-targets",
			"#   aws-cdk.aws-lambda",
			"#   aws-cdk.core"
		]
	},
	"cdk_import": {
		"description": "AWS CDK Import",
		"prefix": [
			"cdk_import"
		],
		"body": [
			"from aws_cdk import (",
			"  core,",
			"  aws_lambda as _lambda,",
			"  aws_apigateway as _apigw,",
			"  aws_s3 as _s3",
			")"
		]
	},
	"cdk_app": {
		"description": "AWS CDK App",
		"prefix": [
			"cdk_app"
		],
		"body": [
			"app = core.App()",
			"ApiCorsLambdaStack(app, \"${1:MyStack}\")",
			"app.synth()"
		]
	},
	"cdk_stack": {
		"description": "AWS CDK Stack",
		"prefix": [
			"cdk_stack"
		],
		"body": [
			"class ${1:MyStack}(core.Stack): ",
			"  def __init__(self, scope: core.Construct, id: str, **kwargs) -> None:",
			"    super().__init__(scope, id, **kwargs)",
			"    $0"
		]
	},
	"cdk_lambda": {
		"description": "AWS CDK Lambda",
		"prefix": [
			"cdk_lambda"
		],
		"body": [
			"lambdaFn = lambda_.Function(",
			"  self,",
			"  'Singleton',",
			"  code=lambda_.InlineCode(handler_code),",
			"  handler='index.main',",
			"  timeout=core.Duration.seconds(300),",
			"  runtime=lambda_.Runtime.PYTHON_3_7,",
			")"
		]
	},
	"cdk_cron": {
		"description": "AWS CDK Cron rule",
		"prefix": [
			"cdk_cron"
		],
		"body": [
			"rule = events.Rule(",
			"  self,",
			"  'Rule',",
			"  schedule=events.Schedule.cron(",
			"    year='*',",
			"    month='*',",
			"    week_day='MON-FRI',",
			"    hour='18',",
			"    minute='0'",
			"  ),",
			")",
			"rule.add_target(targets.LambdaFunction(lambdaFn))",
		]
	},
	"cdk_s3": {
		"description": "AWS CDK S3 bucket",
		"prefix": [
			"cdk_s3",
			"bucket",
			"cdk_bucket"
		],
		"body": [
			"s3 = _s3.Bucket(self, 's3bucket')"
		]
	},
	"autopep8": {
		"description": "Add comments to assist in installing pep8 and running pep8",
		"prefix": [
			"autopep8",
			"pep8",
			"autopep8_help",
			"autopep8_comment",
			"pep8_help",
			"pep8_comment"
		],
		"body": [
			"# pip install --upgrade autopep8",
			"# autopep8 --in-place --aggressive --aggressive <filename>"
		]
	},
	"args": {
		"description": "Get STDIO / CLI args",
		"prefix": [
			"args",
			"py_args",
			"cli_args"
		],
		"body": [
			"import sys",
			"print('This is the name of the script: ', sys.argv[0])",
			"print('Number of arguments: ', len(sys.argv))",
			"print('The arguments are: ' , str(sys.argv))",
		]
	},
	"dir_files": {
		"description": "List all files in dir",
		"prefix": [
			"dir_files",
			"listdir",
			"list_dir",
			"dirfiles"
		],
		"body": [
			"from os import listdir",
			"from os.path import isfile, join",
			"onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
		]
	},
	"jupyter_cell": {
		"description": "Jupyter inline cell (VSCode)",
		"prefix": [
			"jupyter_cell",
			"cell"
		],
		"body": [
			"#%%"
		]
	},
	"jinja": {
		"description": "Jinja html template file",
		"prefix": [
			"jinja",
			"jinja_html",
			"html",
			"html_template"
		],
		"body": [
			"from jinja2 import Environment, FileSystemLoader",
			"env = Environment(loader=FileSystemLoader('.'))",
			"template = env.get_template('myreport.html')",
			"html_out = template.render({\"my_df_table\": df.to_html()})"
		]
	},
	"import_yml": {
		"prefix": [
			"import_yml",
			"import_yaml"
		],
		"description": "Import pyyaml library",
		"body": [
			"import yaml"
		]
	},
	"yml": {
		"prefix": [
			"yml",
			"yaml",
			"load_yml",
			"load_yaml"
		],
		"description": "Load a yaml file",
		"body": [
			"with open('example.yaml', 'r') as f:",
			"\tprint(yaml.safe_load(f))"
		]
	},
}